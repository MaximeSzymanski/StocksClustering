{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering Stocks with a Self-Organizing Map (SOM)\n",
    "\n",
    "In this project, we aim to cluster stocks based on their daily price variation using a Self-Organizing Map (SOM) algorithm. The SOM is a type of artificial neural network that can learn the underlying structure of high-dimensional data and group similar data points together.\n",
    "\n",
    "To begin, we'll retrieve the list of tickers for the S&P600 companies from Wikipedia using web scraping techniques with Python libraries such as BeautifulSoup and requests. The S&P600 is an index of small-cap stocks in the United States, making it a relevant choice for this project.\n",
    "\n",
    "Next, we'll use the yfinance API to collect historical stock prices for each company in the S&P600 over the past five years. We'll then preprocess and clean the data to ensure that each stock has equal weight in the clustering analysis.\n",
    "\n",
    "After the data has been cleaned, we'll compute the daily returns for each stock by calculating the percentage change in price from one day to the next. This allows us to capture the relative price variation over time, which is an important factor in clustering stocks.\n",
    "\n",
    "Finally, we'll use the SOM algorithm to cluster the stocks into groups with similar daily price variation. This will enable us to identify patterns and similarities between the stocks that may not be immediately apparent from raw price data.\n",
    "\n",
    "Overall, this project will provide a step-by-step guide to clustering stocks with a SOM algorithm, from retrieving the data to interpreting the clustering results.\n",
    "\n",
    "\n",
    "#### Scrap Wikipedia's page\n",
    "\n",
    "This code scrapps the wikipedia S&P600's page, to retrieve the list of tickers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "from minisom import MiniSom\n",
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "# request this url https://en.wikipedia.org/wiki/List_of_S%26P_600_companies\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_600_companies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# get the table by the id constituents\n",
    "table = soup.find('table', {'id': 'constituents'})\n",
    "ticker_list = []\n",
    "# iterate over the tr balise in the table\n",
    "for tr in table.find_all('tr'):\n",
    "    # get the first td balise in the tr balise\n",
    "    td = tr.findAll('td')\n",
    "    # if the td balise is not empty\n",
    "    if td is not None and len(td) > 1:\n",
    "        # get the first a balise in the td balise\n",
    "        a = td[1].find('a')\n",
    "        # if the a balise is not empty\n",
    "        if a is not None:\n",
    "            # get the text of the a balise\n",
    "            ticker = a.text\n",
    "            # add the ticker to the list\n",
    "            ticker_list.append(ticker)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Retrieving Historical Stock Prices\n",
    "\n",
    "Next, we'll use the yfinance API to retrieve historical stock prices for each company in the S&P600. Specifically, we'll be collecting the stock prices for the past five years.\n",
    "\n",
    "To ensure that we have enough data to accurately cluster the stocks, we'll only save the stock prices if there are at least number_of_days / 2 data points available. For example, if number_of_days is set to 252 (the number of trading days in a year), we'll only save the stock prices if there are at least 126 data points available.\n",
    "\n",
    "This ensures that we have enough data to accurately capture the stock price variation over time. If there are not enough data points available, the stock prices will not be saved and will not be included in the clustering analysis.\n",
    "\n",
    "Once we've retrieved and saved the historical stock prices, we'll preprocess and clean the data to prepare it for clustering with the SOM algorithm.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 601\n",
      "0 / 601\n",
      "1 / 601\n",
      "2 / 601\n",
      "3 / 601\n",
      "4 / 601\n",
      "5 / 601\n",
      "6 / 601\n",
      "7 / 601\n",
      "8 / 601\n",
      "9 / 601\n",
      "10 / 601\n",
      "11 / 601\n",
      "12 / 601\n",
      "13 / 601\n",
      "14 / 601\n",
      "14 / 601\n",
      "15 / 601\n",
      "16 / 601\n",
      "17 / 601\n",
      "18 / 601\n",
      "19 / 601\n",
      "20 / 601\n",
      "21 / 601\n",
      "22 / 601\n",
      "23 / 601\n",
      "24 / 601\n",
      "25 / 601\n",
      "26 / 601\n",
      "27 / 601\n",
      "28 / 601\n",
      "29 / 601\n",
      "30 / 601\n",
      "31 / 601\n",
      "32 / 601\n",
      "33 / 601\n",
      "34 / 601\n",
      "35 / 601\n",
      "36 / 601\n",
      "37 / 601\n",
      "38 / 601\n",
      "39 / 601\n",
      "40 / 601\n",
      "41 / 601\n",
      "42 / 601\n",
      "43 / 601\n",
      "44 / 601\n",
      "45 / 601\n",
      "45 / 601\n",
      "46 / 601\n",
      "47 / 601\n",
      "48 / 601\n",
      "48 / 601\n",
      "49 / 601\n",
      "50 / 601\n",
      "51 / 601\n",
      "52 / 601\n",
      "53 / 601\n",
      "54 / 601\n",
      "55 / 601\n",
      "56 / 601\n",
      "57 / 601\n",
      "58 / 601\n",
      "59 / 601\n",
      "60 / 601\n",
      "61 / 601\n",
      "62 / 601\n",
      "63 / 601\n",
      "64 / 601\n",
      "65 / 601\n",
      "66 / 601\n",
      "67 / 601\n",
      "68 / 601\n",
      "69 / 601\n",
      "70 / 601\n",
      "71 / 601\n",
      "72 / 601\n",
      "73 / 601\n",
      "74 / 601\n",
      "75 / 601\n",
      "76 / 601\n",
      "77 / 601\n",
      "78 / 601\n",
      "79 / 601\n",
      "80 / 601\n",
      "81 / 601\n",
      "82 / 601\n",
      "83 / 601\n",
      "84 / 601\n",
      "85 / 601\n",
      "86 / 601\n",
      "87 / 601\n",
      "88 / 601\n",
      "89 / 601\n",
      "90 / 601\n",
      "91 / 601\n",
      "92 / 601\n",
      "93 / 601\n",
      "94 / 601\n",
      "95 / 601\n",
      "96 / 601\n",
      "97 / 601\n",
      "98 / 601\n",
      "99 / 601\n",
      "99 / 601\n",
      "100 / 601\n",
      "101 / 601\n",
      "102 / 601\n",
      "103 / 601\n",
      "104 / 601\n",
      "104 / 601\n",
      "105 / 601\n",
      "106 / 601\n",
      "107 / 601\n",
      "108 / 601\n",
      "109 / 601\n",
      "110 / 601\n",
      "111 / 601\n",
      "112 / 601\n",
      "113 / 601\n",
      "114 / 601\n",
      "115 / 601\n",
      "116 / 601\n",
      "117 / 601\n",
      "118 / 601\n",
      "119 / 601\n",
      "120 / 601\n",
      "121 / 601\n",
      "122 / 601\n",
      "123 / 601\n",
      "124 / 601\n",
      "125 / 601\n",
      "126 / 601\n",
      "127 / 601\n",
      "128 / 601\n",
      "129 / 601\n",
      "130 / 601\n",
      "131 / 601\n",
      "132 / 601\n",
      "133 / 601\n",
      "134 / 601\n",
      "135 / 601\n",
      "135 / 601\n",
      "136 / 601\n",
      "136 / 601\n",
      "137 / 601\n",
      "138 / 601\n",
      "139 / 601\n",
      "140 / 601\n",
      "141 / 601\n",
      "142 / 601\n",
      "143 / 601\n",
      "144 / 601\n",
      "145 / 601\n",
      "146 / 601\n",
      "147 / 601\n",
      "148 / 601\n",
      "149 / 601\n",
      "150 / 601\n",
      "151 / 601\n",
      "152 / 601\n",
      "153 / 601\n",
      "154 / 601\n",
      "155 / 601\n",
      "156 / 601\n",
      "157 / 601\n",
      "158 / 601\n",
      "159 / 601\n",
      "160 / 601\n",
      "161 / 601\n",
      "162 / 601\n",
      "163 / 601\n",
      "164 / 601\n",
      "164 / 601\n",
      "165 / 601\n",
      "166 / 601\n",
      "166 / 601\n",
      "167 / 601\n",
      "168 / 601\n",
      "169 / 601\n",
      "170 / 601\n",
      "171 / 601\n",
      "172 / 601\n",
      "173 / 601\n",
      "174 / 601\n",
      "175 / 601\n",
      "176 / 601\n",
      "177 / 601\n",
      "177 / 601\n",
      "178 / 601\n",
      "179 / 601\n",
      "179 / 601\n",
      "180 / 601\n",
      "181 / 601\n",
      "182 / 601\n",
      "183 / 601\n",
      "184 / 601\n",
      "185 / 601\n",
      "186 / 601\n",
      "187 / 601\n",
      "188 / 601\n",
      "189 / 601\n",
      "190 / 601\n",
      "191 / 601\n",
      "192 / 601\n",
      "193 / 601\n",
      "194 / 601\n",
      "195 / 601\n",
      "195 / 601\n",
      "196 / 601\n",
      "197 / 601\n",
      "198 / 601\n",
      "199 / 601\n",
      "200 / 601\n",
      "201 / 601\n",
      "202 / 601\n",
      "203 / 601\n",
      "204 / 601\n",
      "205 / 601\n",
      "206 / 601\n",
      "207 / 601\n",
      "208 / 601\n",
      "209 / 601\n",
      "210 / 601\n",
      "211 / 601\n",
      "212 / 601\n",
      "213 / 601\n",
      "214 / 601\n",
      "215 / 601\n",
      "216 / 601\n",
      "217 / 601\n",
      "218 / 601\n",
      "219 / 601\n",
      "220 / 601\n",
      "221 / 601\n",
      "222 / 601\n",
      "223 / 601\n",
      "224 / 601\n",
      "225 / 601\n",
      "226 / 601\n",
      "227 / 601\n",
      "228 / 601\n",
      "229 / 601\n",
      "230 / 601\n",
      "231 / 601\n",
      "232 / 601\n",
      "233 / 601\n",
      "234 / 601\n",
      "235 / 601\n",
      "236 / 601\n",
      "237 / 601\n",
      "238 / 601\n",
      "239 / 601\n",
      "240 / 601\n",
      "241 / 601\n",
      "242 / 601\n",
      "243 / 601\n",
      "244 / 601\n",
      "245 / 601\n",
      "246 / 601\n",
      "247 / 601\n",
      "248 / 601\n",
      "249 / 601\n",
      "250 / 601\n",
      "251 / 601\n",
      "251 / 601\n",
      "252 / 601\n",
      "253 / 601\n",
      "254 / 601\n",
      "255 / 601\n",
      "256 / 601\n",
      "257 / 601\n",
      "258 / 601\n",
      "259 / 601\n",
      "260 / 601\n",
      "261 / 601\n",
      "262 / 601\n",
      "263 / 601\n",
      "264 / 601\n",
      "265 / 601\n",
      "266 / 601\n",
      "267 / 601\n",
      "268 / 601\n",
      "269 / 601\n",
      "270 / 601\n",
      "271 / 601\n",
      "272 / 601\n",
      "273 / 601\n",
      "274 / 601\n",
      "275 / 601\n",
      "276 / 601\n",
      "277 / 601\n",
      "278 / 601\n",
      "278 / 601\n",
      "279 / 601\n",
      "280 / 601\n",
      "281 / 601\n",
      "282 / 601\n",
      "283 / 601\n",
      "284 / 601\n",
      "285 / 601\n",
      "286 / 601\n",
      "287 / 601\n",
      "288 / 601\n",
      "289 / 601\n",
      "290 / 601\n",
      "291 / 601\n",
      "292 / 601\n",
      "293 / 601\n",
      "294 / 601\n",
      "295 / 601\n",
      "296 / 601\n",
      "297 / 601\n",
      "298 / 601\n",
      "299 / 601\n",
      "300 / 601\n",
      "300 / 601\n",
      "301 / 601\n",
      "302 / 601\n",
      "303 / 601\n",
      "304 / 601\n",
      "305 / 601\n",
      "306 / 601\n",
      "307 / 601\n",
      "LPI: No data found, symbol may be delisted\n",
      "307 / 601\n",
      "308 / 601\n",
      "309 / 601\n",
      "310 / 601\n",
      "311 / 601\n",
      "312 / 601\n",
      "313 / 601\n",
      "314 / 601\n",
      "315 / 601\n",
      "316 / 601\n",
      "317 / 601\n",
      "317 / 601\n",
      "318 / 601\n",
      "319 / 601\n",
      "319 / 601\n",
      "320 / 601\n",
      "321 / 601\n",
      "322 / 601\n",
      "323 / 601\n",
      "324 / 601\n",
      "325 / 601\n",
      "326 / 601\n",
      "327 / 601\n",
      "328 / 601\n",
      "329 / 601\n",
      "330 / 601\n",
      "331 / 601\n",
      "332 / 601\n",
      "333 / 601\n",
      "334 / 601\n",
      "335 / 601\n",
      "MOG.A: No data found, symbol may be delisted\n",
      "335 / 601\n",
      "336 / 601\n",
      "337 / 601\n",
      "338 / 601\n",
      "339 / 601\n",
      "340 / 601\n",
      "341 / 601\n",
      "342 / 601\n",
      "343 / 601\n",
      "344 / 601\n",
      "345 / 601\n",
      "346 / 601\n",
      "347 / 601\n",
      "348 / 601\n",
      "349 / 601\n",
      "350 / 601\n",
      "351 / 601\n",
      "352 / 601\n",
      "353 / 601\n",
      "354 / 601\n",
      "355 / 601\n",
      "356 / 601\n",
      "357 / 601\n",
      "358 / 601\n",
      "359 / 601\n",
      "360 / 601\n",
      "361 / 601\n",
      "362 / 601\n",
      "363 / 601\n",
      "364 / 601\n",
      "365 / 601\n",
      "366 / 601\n",
      "367 / 601\n",
      "368 / 601\n",
      "369 / 601\n",
      "370 / 601\n",
      "371 / 601\n",
      "372 / 601\n",
      "373 / 601\n",
      "374 / 601\n",
      "375 / 601\n",
      "375 / 601\n",
      "375 / 601\n",
      "376 / 601\n",
      "377 / 601\n",
      "378 / 601\n",
      "379 / 601\n",
      "380 / 601\n",
      "381 / 601\n",
      "382 / 601\n",
      "383 / 601\n",
      "384 / 601\n",
      "384 / 601\n",
      "385 / 601\n",
      "386 / 601\n",
      "387 / 601\n",
      "388 / 601\n",
      "389 / 601\n",
      "390 / 601\n",
      "391 / 601\n",
      "392 / 601\n",
      "393 / 601\n",
      "394 / 601\n",
      "395 / 601\n",
      "396 / 601\n",
      "397 / 601\n",
      "398 / 601\n",
      "399 / 601\n",
      "400 / 601\n",
      "401 / 601\n",
      "402 / 601\n",
      "403 / 601\n",
      "404 / 601\n",
      "405 / 601\n",
      "406 / 601\n",
      "407 / 601\n",
      "408 / 601\n",
      "409 / 601\n",
      "410 / 601\n",
      "411 / 601\n",
      "412 / 601\n",
      "413 / 601\n",
      "414 / 601\n",
      "415 / 601\n",
      "416 / 601\n",
      "417 / 601\n",
      "418 / 601\n",
      "419 / 601\n",
      "420 / 601\n",
      "421 / 601\n",
      "422 / 601\n",
      "423 / 601\n",
      "424 / 601\n",
      "425 / 601\n",
      "426 / 601\n",
      "427 / 601\n",
      "428 / 601\n",
      "429 / 601\n",
      "430 / 601\n",
      "431 / 601\n",
      "432 / 601\n",
      "433 / 601\n",
      "434 / 601\n",
      "435 / 601\n",
      "436 / 601\n",
      "437 / 601\n",
      "438 / 601\n",
      "439 / 601\n",
      "440 / 601\n",
      "440 / 601\n",
      "441 / 601\n",
      "442 / 601\n",
      "443 / 601\n",
      "444 / 601\n",
      "445 / 601\n",
      "446 / 601\n",
      "447 / 601\n",
      "448 / 601\n",
      "449 / 601\n",
      "450 / 601\n",
      "451 / 601\n",
      "452 / 601\n",
      "453 / 601\n",
      "454 / 601\n",
      "455 / 601\n",
      "456 / 601\n",
      "457 / 601\n",
      "458 / 601\n",
      "459 / 601\n",
      "460 / 601\n",
      "461 / 601\n",
      "462 / 601\n",
      "463 / 601\n",
      "464 / 601\n",
      "465 / 601\n",
      "466 / 601\n",
      "467 / 601\n",
      "468 / 601\n",
      "469 / 601\n",
      "470 / 601\n",
      "471 / 601\n",
      "471 / 601\n",
      "472 / 601\n",
      "473 / 601\n",
      "474 / 601\n",
      "475 / 601\n",
      "476 / 601\n",
      "476 / 601\n",
      "477 / 601\n",
      "478 / 601\n",
      "479 / 601\n",
      "480 / 601\n",
      "481 / 601\n",
      "482 / 601\n",
      "483 / 601\n",
      "484 / 601\n",
      "485 / 601\n",
      "486 / 601\n",
      "487 / 601\n",
      "488 / 601\n",
      "489 / 601\n",
      "490 / 601\n",
      "491 / 601\n",
      "SWM: No data found, symbol may be delisted\n",
      "491 / 601\n",
      "492 / 601\n",
      "493 / 601\n",
      "494 / 601\n",
      "495 / 601\n",
      "496 / 601\n",
      "TBK: No data found, symbol may be delisted\n",
      "496 / 601\n",
      "497 / 601\n",
      "498 / 601\n",
      "499 / 601\n",
      "500 / 601\n",
      "501 / 601\n",
      "502 / 601\n",
      "503 / 601\n",
      "504 / 601\n",
      "505 / 601\n",
      "506 / 601\n",
      "507 / 601\n",
      "508 / 601\n",
      "509 / 601\n",
      "510 / 601\n",
      "511 / 601\n",
      "512 / 601\n",
      "513 / 601\n",
      "514 / 601\n",
      "515 / 601\n",
      "516 / 601\n",
      "517 / 601\n",
      "518 / 601\n",
      "519 / 601\n",
      "520 / 601\n",
      "521 / 601\n",
      "522 / 601\n",
      "523 / 601\n",
      "524 / 601\n",
      "525 / 601\n",
      "526 / 601\n",
      "527 / 601\n",
      "528 / 601\n",
      "529 / 601\n",
      "530 / 601\n",
      "531 / 601\n",
      "532 / 601\n",
      "533 / 601\n",
      "534 / 601\n",
      "535 / 601\n",
      "536 / 601\n",
      "537 / 601\n",
      "538 / 601\n",
      "539 / 601\n",
      "540 / 601\n",
      "541 / 601\n",
      "541 / 601\n",
      "542 / 601\n",
      "543 / 601\n",
      "544 / 601\n",
      "545 / 601\n",
      "546 / 601\n",
      "547 / 601\n",
      "548 / 601\n",
      "549 / 601\n",
      "550 / 601\n",
      "551 / 601\n",
      "552 / 601\n",
      "553 / 601\n",
      "554 / 601\n",
      "555 / 601\n",
      "WETF: No data found, symbol may be delisted\n",
      "555 / 601\n",
      "556 / 601\n",
      "557 / 601\n",
      "558 / 601\n",
      "WRE: No data found, symbol may be delisted\n",
      "558 / 601\n",
      "559 / 601\n",
      "560 / 601\n",
      "561 / 601\n",
      "562 / 601\n",
      "563 / 601\n",
      "564 / 601\n",
      "565 / 601\n",
      "565 / 601\n",
      "566 / 601\n",
      "567 / 601\n",
      "568 / 601\n"
     ]
    },
    {
     "data": {
      "text/plain": "569"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "df_list = []\n",
    "period = '5y'\n",
    "number_of_days = 5*365\n",
    "ticker_downloaded = []\n",
    "for ticker in ticker_list:\n",
    "    print(index, '/', len(ticker_list))\n",
    "    df_temp = yf.Ticker(ticker).history(period='5y')\n",
    "    if len(df_temp) < number_of_days//2:\n",
    "        continue\n",
    "    else:\n",
    "        df_temp['Daily Return'] = df_temp['Close'].pct_change()\n",
    "        ticker_downloaded.append(ticker)\n",
    "        df_list.append(df_temp)\n",
    "    index += 1\n",
    "len(df_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_list_daily_return = []\n",
    "for df in df_list:\n",
    "    df_list_daily_return.append(df['Daily Return'])\n",
    "\n",
    "[df.dropna(inplace=True) for df in df_list_daily_return]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the first 100 series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the first 100 series\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(20,5,figsize=(25,25))\n",
    "fig.suptitle('Series')\n",
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        if i*4+j+1>len(df_list_daily_return): # pass the others that we can't fill\n",
    "            continue\n",
    "        axs[i, j].plot(df_list_daily_return[i*4+j].values)\n",
    "        axs[i, j].set_title(ticker_downloaded[i*4+j])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series_lengths = {len(series) for series in df_list_daily_return}\n",
    "print(series_lengths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find the longest series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len = max(series_lengths)\n",
    "longest_series = None\n",
    "for series in df_list_daily_return:\n",
    "    if len(series) == max_len:\n",
    "        longest_series = series\n",
    "print(len(longest_series))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reindex all series based on the longest one, and fill them with NaNs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "problems_index = []\n",
    "\n",
    "for i in range(len(df_list_daily_return)):\n",
    "    if len(df_list_daily_return[i])!= max_len:\n",
    "        problems_index.append(i)\n",
    "        df_list_daily_return[i] = df_list_daily_return[i].reindex(longest_series.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def nan_counter(list_of_series):\n",
    "    nan_polluted_series_counter = 0\n",
    "    for series in list_of_series:\n",
    "        if series.isnull().sum().sum() > 0:\n",
    "            nan_polluted_series_counter+=1\n",
    "    print(nan_polluted_series_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nan_counter(df_list_daily_return)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Interpolate the NaNs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in problems_index:\n",
    "    df_list_daily_return[i].interpolate(limit_direction=\"both\",inplace=True, method='linear')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nan_counter(df_list_daily_return)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_list_daily_return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalize the data between 0 and 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for i in range(len(df_list_daily_return)):\n",
    "    scaler = MinMaxScaler()\n",
    "    df_list_daily_return[i] = MinMaxScaler().fit_transform(df_list_daily_return[i].values.reshape(-1,1))\n",
    "    df_list_daily_return[i]= df_list_daily_return[i].reshape(len(df_list_daily_return[i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"max: \"+str(max(df_list_daily_return[0]))+\"\\tmin: \"+str(min(df_list_daily_return[0])))\n",
    "print(df_list_daily_return[0][:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the SOM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "som_x = som_y = math.ceil(math.sqrt(math.sqrt(len(df_list_daily_return))))\n",
    "\n",
    "som = MiniSom(som_x, som_y,len(df_list_daily_return[0]), sigma=1, learning_rate = 0.0001)\n",
    "\n",
    "som.random_weights_init(df_list_daily_return)\n",
    "som.train(df_list_daily_return, 100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_som_series_averaged_center(som_x, som_y, win_map):\n",
    "    fig, axs = plt.subplots(som_x,som_y,figsize=(25,25))\n",
    "    fig.suptitle('Clusters')\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            if cluster in win_map.keys():\n",
    "                for series in win_map[cluster]:\n",
    "                    axs[cluster].plot(series,c=\"gray\",alpha=0.5)\n",
    "                axs[cluster].plot(np.average(np.vstack(win_map[cluster]),axis=0),c=\"red\")\n",
    "            cluster_number = x*som_y+y+1\n",
    "            axs[cluster].set_title(f\"Cluster {cluster_number}\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the clusters\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "win_map = som.win_map(df_list_daily_return)\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print the tickers of each cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtenir la carte des nœuds gagnants\n",
    "win_map = som.win_map(df_list_daily_return)\n",
    "\n",
    "# Initialiser une liste de labels pour chaque cluster\n",
    "cluster_labels = [[] for i in range(som_x * som_y)]\n",
    "\n",
    "# Parcourir la liste de données et extraire les labels correspondants à chaque cluster\n",
    "for i, data in enumerate(df_list_daily_return):\n",
    "    # Trouver le nœud gagnant correspondant à la série de données\n",
    "    node = som.winner(data)\n",
    "    # Ajouter le label correspondant à la série de données à la liste de labels du cluster correspondant\n",
    "    cluster_labels[node[0] * som_y + node[1]].append(ticker_downloaded[i])\n",
    "\n",
    "# Afficher les labels pour chaque cluster\n",
    "for i in range(som_x * som_y):\n",
    "    print(\"Cluster \", i+1, \" : \", cluster_labels[i])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot all close values of a cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_number = 19\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(25,25))\n",
    "fig.suptitle('Clusters')\n",
    "for ticker in cluster_labels[cluster_number]:\n",
    "    axs.plot(df_list[ticker_downloaded.index(ticker)]['Close'].values)\n",
    "    axs.set_title(f\"Cluster {cluster_number}\")\n",
    "axs.legend(cluster_labels[cluster_number])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
