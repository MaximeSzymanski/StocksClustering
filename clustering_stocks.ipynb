{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering of stocks\n",
    "\n",
    "This project will show how to cluster stocks. The tickers of the **S&P600** companies are scrapped from wikipedia. Then, the yfinance API is used to get the stocks prices of all those companies.\n",
    "The data are then **preprossed, cleaned and formalized**.\n",
    "Finally, a SOM is used to **clusterise** the stock by group that have the same close price variation.\n",
    "\n",
    "\n",
    "\n",
    "## Scrap Wikipedia's page\n",
    "\n",
    "This code scrapps the wikipedia S&P600's page, to retrieve the list of tickers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "from minisom import MiniSom\n",
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "# request this url https://en.wikipedia.org/wiki/List_of_S%26P_600_companies\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_600_companies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# get the table by the id constituents\n",
    "table = soup.find('table', {'id': 'constituents'})\n",
    "ticker_list = []\n",
    "# iterate over the tr balise in the table\n",
    "for tr in table.find_all('tr'):\n",
    "    # get the first td balise in the tr balise\n",
    "    td = tr.findAll('td')\n",
    "    # if the td balise is not empty\n",
    "    if td is not None and len(td) > 1:\n",
    "        # get the first a balise in the td balise\n",
    "        a = td[1].find('a')\n",
    "        # if the a balise is not empty\n",
    "        if a is not None:\n",
    "            # get the text of the a balise\n",
    "            ticker = a.text\n",
    "            # add the ticker to the list\n",
    "            ticker_list.append(ticker)\n",
    "# pr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 0\n",
    "df_list = []\n",
    "period = '5y'\n",
    "number_of_days = 5*365\n",
    "ticker_downloaded = []\n",
    "for ticker in ticker_list:\n",
    "    print(index, '/', len(ticker_list))\n",
    "    df_temp = yf.Ticker(ticker).history(period='5y')\n",
    "    if len(df_temp) < number_of_days//2:\n",
    "        continue\n",
    "    else:\n",
    "        df_temp['Daily Return'] = df_temp['Close'].pct_change()\n",
    "        ticker_downloaded.append(ticker)\n",
    "        df_list.append(df_temp)\n",
    "    index += 1\n",
    "len(df_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (97892223.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[2], line 4\u001B[0;36m\u001B[0m\n\u001B[0;31m    The daily returns are then computed for each stocks values.\u001B[0m\n\u001B[0m        ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# create a new dataframe list with only the daily return\n",
    "df_list_daily_return = []\n",
    "for df in df_list:\n",
    "    df_list_daily_return.append(df['Daily Return'])\n",
    "\n",
    "[df.dropna(inplace=True) for df in df_list_daily_return]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the first 100 series\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(20,5,figsize=(25,25))\n",
    "fig.suptitle('Series')\n",
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        if i*4+j+1>len(df_list_daily_return): # pass the others that we can't fill\n",
    "            continue\n",
    "        axs[i, j].plot(df_list_daily_return[i*4+j].values)\n",
    "        axs[i, j].set_title(ticker_downloaded[i*4+j])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series_lengths = {len(series) for series in df_list_daily_return}\n",
    "print(series_lengths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len = max(series_lengths)\n",
    "longest_series = None\n",
    "for series in df_list_daily_return:\n",
    "    if len(series) == max_len:\n",
    "        longest_series = series\n",
    "print(len(longest_series))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "problems_index = []\n",
    "\n",
    "for i in range(len(df_list_daily_return)):\n",
    "    if len(df_list_daily_return[i])!= max_len:\n",
    "        problems_index.append(i)\n",
    "        df_list_daily_return[i] = df_list_daily_return[i].reindex(longest_series.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def nan_counter(list_of_series):\n",
    "    nan_polluted_series_counter = 0\n",
    "    for series in list_of_series:\n",
    "        if series.isnull().sum().sum() > 0:\n",
    "            nan_polluted_series_counter+=1\n",
    "    print(nan_polluted_series_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nan_counter(df_list_daily_return)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in problems_index:\n",
    "    df_list_daily_return[i].interpolate(limit_direction=\"both\",inplace=True, method='linear')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nan_counter(df_list_daily_return)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_list_daily_return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for i in range(len(df_list_daily_return)):\n",
    "    scaler = MinMaxScaler()\n",
    "    df_list_daily_return[i] = MinMaxScaler().fit_transform(df_list_daily_return[i].values.reshape(-1,1))\n",
    "    df_list_daily_return[i]= df_list_daily_return[i].reshape(len(df_list_daily_return[i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"max: \"+str(max(df_list_daily_return[0]))+\"\\tmin: \"+str(min(df_list_daily_return[0])))\n",
    "print(df_list_daily_return[0][:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "som_x = som_y = math.ceil(math.sqrt(math.sqrt(len(df_list_daily_return))))\n",
    "# I didn't see its significance but to make the map square,\n",
    "# I calculated square root of map size which is\n",
    "# the square root of the number of series\n",
    "# for the row and column counts of som\n",
    "\n",
    "som = MiniSom(som_x, som_y,len(df_list_daily_return[0]), sigma=1, learning_rate = 0.0001)\n",
    "\n",
    "som.random_weights_init(df_list_daily_return)\n",
    "som.train(df_list_daily_return, 100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Little handy function to plot series\n",
    "def plot_som_series_averaged_center(som_x, som_y, win_map):\n",
    "    fig, axs = plt.subplots(som_x,som_y,figsize=(25,25))\n",
    "    fig.suptitle('Clusters')\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            if cluster in win_map.keys():\n",
    "                for series in win_map[cluster]:\n",
    "                    axs[cluster].plot(series,c=\"gray\",alpha=0.5)\n",
    "                axs[cluster].plot(np.average(np.vstack(win_map[cluster]),axis=0),c=\"red\")\n",
    "            cluster_number = x*som_y+y+1\n",
    "            axs[cluster].set_title(f\"Cluster {cluster_number}\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "win_map = som.win_map(df_list_daily_return)\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtenir la carte des nœuds gagnants\n",
    "win_map = som.win_map(df_list_daily_return)\n",
    "\n",
    "# Initialiser une liste de labels pour chaque cluster\n",
    "cluster_labels = [[] for i in range(som_x * som_y)]\n",
    "\n",
    "# Parcourir la liste de données et extraire les labels correspondants à chaque cluster\n",
    "for i, data in enumerate(df_list_daily_return):\n",
    "    # Trouver le nœud gagnant correspondant à la série de données\n",
    "    node = som.winner(data)\n",
    "    # Ajouter le label correspondant à la série de données à la liste de labels du cluster correspondant\n",
    "    cluster_labels[node[0] * som_y + node[1]].append(ticker_downloaded[i])\n",
    "\n",
    "# Afficher les labels pour chaque cluster\n",
    "for i in range(som_x * som_y):\n",
    "    print(\"Cluster \", i+1, \" : \", cluster_labels[i])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot each Close price of the stocks in the same cluster, cluster 1, in the same plot\n",
    "# The close price is df_list['Close']\n",
    "\n",
    "cluster_number = 19\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(25,25))\n",
    "fig.suptitle('Clusters')\n",
    "for ticker in cluster_labels[cluster_number]:\n",
    "    axs.plot(df_list[ticker_downloaded.index(ticker)]['Close'].values)\n",
    "    axs.set_title(f\"Cluster {cluster_number}\")\n",
    "axs.legend(cluster_labels[cluster_number])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
